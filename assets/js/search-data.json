{
  
    
        "post0": {
            "title": "Step 3",
            "content": "Now that we inputted good and usable data for the model to learn from, we can use the predictions that have been made thus far to find how accurate they are. . predictions = backtest(weather, rr, predictors) from sklearn.metrics import mean_absolute_error, mean_squared_error mean_absolute_error(predictions[&quot;actual&quot;], predictions[&quot;prediction&quot;]) . The output of this code should tell us the mean error of all the predictions. In this case, we have a mean absolute error of 5.13932667966084 . this means that on average, our predictions were about 5 degrees off . def pct_diff(old, new): return (new - old) / old def compute_rolling(weather, horizon, col): label = f&quot;rolling_{horizon}_{col}&quot; weather[label] = weather[col].rolling(horizon).mean() weather[f&quot;{label}_pct&quot;] = pct_diff(weather[label], weather[col]) return weather rolling_horizons = [3, 14] for horizon in rolling_horizons: for col in [&quot;tmax&quot;, &quot;tmin&quot;, &quot;prcp&quot;]: weather = compute_rolling(weather, horizon, col) . The function pct_diff takes two parameters, old and new, and calculates the percentage difference between them by subtracting old from new and dividing the result by old. It returns the computed percentage difference. . The function compute_rolling takes three parameters, weather (a DataFrame containing weather data), horizon (an integer representing the rolling window size), and col (a string specifying the column name to compute rolling averages and percentage differences for). . Inside the compute_rolling function, a label variable is created using f-string formatting to represent the rolling computation being performed. For example, if horizon is 3 and col is &quot;tmax&quot;, the label will be &quot;rolling_3_tmax&quot;. . The weather DataFrame is modified by adding a new column with the label computed above (weather[label]). This column represents the rolling average of the specified col over the given horizon. It is calculated using the rolling method of the DataFrame with the mean function applied to the specified col and a window size of horizon. . Another new column is added to the weather DataFrame, representing the percentage difference between the rolling average and the original col values. The new column&#39;s label is created by appending &quot;_pct&quot; to the rolling label (e.g., &quot;rolling_3_tmax_pct&quot;). The pct_diff function is called to calculate the percentage difference using the rolling average column and the original col column as inputs. . The modified weather DataFrame is returned from the compute_rolling function. . A list called rolling_horizons is defined, which contains the horizon values for the rolling computation. . A nested loop is used to iterate over each horizon in the rolling_horizons list and each col in the list [&quot;tmax&quot;, &quot;tmin&quot;, &quot;prcp&quot;]. . Inside the nested loop, the compute_rolling function is called to compute rolling averages and percentage differences for the current horizon and col values. The modified weather DataFrame is assigned back to the weather variable, effectively updating it with the new columns. . In summary, this code calculates rolling averages and percentage differences for specified columns in a weather DataFrame. It iterates over different rolling window sizes (horizon) and columns (col) to perform the computations and modifies the DataFrame accordingly. .",
            "url": "https://sarayu-pr11.github.io/sarayucsa/jupyter/2023/05/31/step3.html",
            "relUrl": "/jupyter/2023/05/31/step3.html",
            "date": " • May 31, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "Step 2",
            "content": "After data cleaning . This is when you have to start assigning variables and labels to every instance, but before that, we need to make sure every spot has a value, even if it is wrong. . weather = weather.ffill() #pull the temperature from a specific row and fil it in #in this case the last value #even though the value is wrong, we can&#39;t have missing values . Now we start the predictions. Since we have multiple independent variables in the data (snow, rain, sleet, temperature), the data suffers from multicolinearity. Since this is the case, we need to use ridge regression. This type of model assumes that there is some sort of association between each of the variables and creates a prediction model accordingly. . from sklearn.linear_model import Ridge rr = Ridge(alpha=.1) #we&#39;re going to apply a ridge regression model since the data sufferes from multicolinearity . def backtest(weather, model, predictors, start=3650, step=90): all_predictions = [] for i in range(start, weather.shape[0], step): train = weather.iloc[:i,:] test = weather.iloc[i:(i+step),:] model.fit(train[predictors], train[&quot;target&quot;]) preds = model.predict(test[predictors]) preds = pd.Series(preds, index=test.index) combined = pd.concat([test[&quot;target&quot;], preds], axis=1) combined.columns = [&quot;actual&quot;, &quot;prediction&quot;] combined[&quot;diff&quot;] = (combined[&quot;prediction&quot;] - combined[&quot;actual&quot;]).abs() all_predictions.append(combined) return pd.concat(all_predictions) . This code performs a backtesting analysis using a machine learning model. . Here is a breakdown of what the code does. . The function takes four parameters as input: weather (a DataFrame containing weather data), model (a machine learning model object), predictors (a list of predictor variables/columns from the weather DataFrame), start (an optional parameter specifying the starting index for the backtesting, default is 3650), and step (an optional parameter specifying the step size for each iteration of the backtesting, default is 90) | It initializes an empty list called all_predictions to store the predictions made during the backtesting. . | It starts a for loop that iterates over the range of indices from start to the total number of rows in the weather DataFrame with a step size of step. This loop allows the backtesting to be performed in multiple iterations with overlapping test sets. . | Within each iteration of the loop, it splits the weather DataFrame into a training set and a test set. The training set (train) includes all rows from the beginning up to the current index i, while the test set (test) includes the rows from i to i+step. . | The machine learning model (model) is trained using the predictor variables (predictors) from the training set (train) and the corresponding target variable (column) named &quot;target&quot; from the training set. . | The trained model is then used to make predictions on the predictor variables from the test set (test[predictors]). The predictions are stored in the preds variable. . | The predicted values are converted to a pandas Series (preds) with the same index as the test set (test.index). . | The actual target values and the predicted values are concatenated together into a DataFrame (combined) using pd.concat(). The columns of the DataFrame are renamed to &quot;actual&quot; and &quot;prediction&quot;. . | A new column named &quot;diff&quot; is added to the DataFrame combined, which represents the absolute difference between the predicted and actual values. . | The DataFrame combined is appended to the all_predictions list. . | After the loop completes, all the prediction results from each iteration are concatenated together using pd.concat() and returned as the final result of the function. . | In summary, this code performs a backtesting analysis by training a machine learning model on the weather data and making predictions on overlapping test sets. It collects the predicted values, actual values, and the absolute difference between them in each iteration and returns the concatenated result. .",
            "url": "https://sarayu-pr11.github.io/sarayucsa/jupyter/2023/05/30/step2.html",
            "relUrl": "/jupyter/2023/05/30/step2.html",
            "date": " • May 30, 2023"
        }
        
    
  
    
        ,"post2": {
            "title": "Weather AI",
            "content": "import pandas as pd #pandas is a data analysis library for python weather = pd.read_csv(&quot;weather.csv&quot;, index_col=&quot;DATE&quot;) # pandas read csv function, reads in weather csv file. specifies that the first colomn (date colomn) is the index . weather . STATION NAME ACMH ACSH AWND FMTM PGTM PRCP SNOW SNWD ... WT11 WT13 WT14 WT15 WT16 WT17 WT18 WT21 WT22 WV01 . DATE . 1970-01-01 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 80.0 | 90.0 | NaN | NaN | NaN | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1970-01-02 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 30.0 | 20.0 | NaN | NaN | NaN | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1970-01-03 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 80.0 | 100.0 | NaN | NaN | NaN | 0.02 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | 1.0 | NaN | 1.0 | NaN | NaN | NaN | . 1970-01-04 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 10.0 | 20.0 | NaN | NaN | NaN | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | 1.0 | NaN | NaN | NaN | . 1970-01-05 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 30.0 | 10.0 | NaN | NaN | NaN | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2022-10-17 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | NaN | NaN | 9.62 | NaN | NaN | 0.08 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2022-10-18 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | NaN | NaN | 12.08 | NaN | NaN | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2022-10-19 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | NaN | NaN | 14.99 | NaN | NaN | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2022-10-20 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | NaN | NaN | 16.78 | NaN | 10.0 | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2022-10-21 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | NaN | NaN | NaN | NaN | NaN | 0.00 | 0.0 | 0.0 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 19287 rows × 44 columns . null_pct = weather.apply(pd.isnull).sum()/weather.shape[0] null_pct #finds the number of null values in each colomn #then divides it by the total number of rows . STATION 0.000000 NAME 0.000000 ACMH 0.501478 ACSH 0.501426 AWND 0.265256 FMTM 0.475087 PGTM 0.363872 PRCP 0.000000 SNOW 0.000000 SNWD 0.000104 TAVG 0.680406 TMAX 0.000000 TMIN 0.000000 TSUN 0.998393 WDF1 0.501685 WDF2 0.498678 WDF5 0.502981 WDFG 0.734484 WDFM 0.999948 WESD 0.685228 WSF1 0.501530 WSF2 0.498678 WSF5 0.503033 WSFG 0.613055 WSFM 0.999948 WT01 0.630217 WT02 0.935034 WT03 0.933271 WT04 0.982579 WT05 0.981127 WT06 0.990615 WT07 0.994400 WT08 0.796962 WT09 0.992741 WT11 0.999274 WT13 0.886711 WT14 0.954010 WT15 0.997822 WT16 0.658993 WT17 0.996889 WT18 0.939493 WT21 0.999741 WT22 0.997459 WV01 0.999948 dtype: float64 . valid_columns = weather.columns[null_pct &lt; .05] . valid_columns #these are the colomns with less than 5% missing values . Index([&#39;STATION&#39;, &#39;NAME&#39;, &#39;PRCP&#39;, &#39;SNOW&#39;, &#39;SNWD&#39;, &#39;TMAX&#39;, &#39;TMIN&#39;], dtype=&#39;object&#39;) . weather = weather[valid_columns].copy() #preserves only the above colomns in our data #.copy() prevents us from getting a copy warning later . weather.columns = weather.columns.str.lower() . weather . station name prcp snow snwd tmax tmin . DATE . 1970-01-01 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 28 | 22 | . 1970-01-02 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 31 | 22 | . 1970-01-03 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.02 | 0.0 | 0.0 | 38 | 25 | . 1970-01-04 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 31 | 23 | . 1970-01-05 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 35 | 21 | . ... ... | ... | ... | ... | ... | ... | ... | . 2022-10-17 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.08 | 0.0 | 0.0 | 67 | 54 | . 2022-10-18 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 58 | 48 | . 2022-10-19 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 56 | 43 | . 2022-10-20 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 61 | 44 | . 2022-10-21 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 64 | 43 | . 19287 rows × 7 columns . weather = weather.ffill() #for example if the last day had a snow depth of 0, then the next day would also probably have a snow depth of zero too . weather.apply(pd.isnull).sum() #now we can see that all the missing values have been filled and we have 0 missing values . station 0 name 0 prcp 0 snow 0 snwd 0 tmax 0 tmin 0 dtype: int64 . weather.apply(pd.isnull).sum() #now we can see that all the missing values have been filled and we have 0 missing values . station 0 name 0 prcp 0 snow 0 snwd 0 tmax 0 tmin 0 dtype: int64 . weather.dtypes #everything is stored as the correct type here #object data type usually indicates that the colomn is a string . station object name object prcp float64 snow float64 snwd float64 tmax int64 tmin int64 dtype: object . weather.index . Index([&#39;1970-01-01&#39;, &#39;1970-01-02&#39;, &#39;1970-01-03&#39;, &#39;1970-01-04&#39;, &#39;1970-01-05&#39;, &#39;1970-01-06&#39;, &#39;1970-01-07&#39;, &#39;1970-01-08&#39;, &#39;1970-01-09&#39;, &#39;1970-01-10&#39;, ... &#39;2022-10-12&#39;, &#39;2022-10-13&#39;, &#39;2022-10-14&#39;, &#39;2022-10-15&#39;, &#39;2022-10-16&#39;, &#39;2022-10-17&#39;, &#39;2022-10-18&#39;, &#39;2022-10-19&#39;, &#39;2022-10-20&#39;, &#39;2022-10-21&#39;], dtype=&#39;object&#39;, name=&#39;DATE&#39;, length=19287) . weather.index = pd.to_datetime(weather.index) . weather.index.year.value_counts().sort_index() #it sorts the index in order by year #counts how many times each unique value occurs, sees how many records we have for each year #should be either 365 or 366 (for leap years) . 1970 365 1971 365 1972 366 1973 365 1974 365 1975 365 1976 366 1977 365 1978 365 1979 365 1980 366 1981 365 1982 365 1983 365 1984 366 1985 365 1986 365 1987 365 1988 366 1989 365 1990 365 1991 365 1992 366 1993 365 1994 365 1995 365 1996 366 1997 365 1998 365 1999 365 2000 366 2001 365 2002 365 2003 365 2004 366 2005 365 2006 365 2007 365 2008 366 2009 365 2010 365 2011 365 2012 366 2013 365 2014 365 2015 365 2016 366 2017 365 2018 365 2019 365 2020 366 2021 365 2022 294 Name: DATE, dtype: int64 . weather[&quot;snwd&quot;].plot() #creates car graph that shows snow depth by day . &lt;AxesSubplot:xlabel=&#39;DATE&#39;&gt; . weather[&quot;target&quot;] = weather.shift(-1)[&quot;tmax&quot;] #creating a target colomn in the weather data for predictions #shift method keeps the same method but pulls value from the next row . weather #for example Jan 1&#39;s target is Jan 2&#39;s Tmax . station name prcp snow snwd tmax tmin target . DATE . 1970-01-01 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 28 | 22 | 31.0 | . 1970-01-02 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 31 | 22 | 38.0 | . 1970-01-03 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.02 | 0.0 | 0.0 | 38 | 25 | 31.0 | . 1970-01-04 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 31 | 23 | 35.0 | . 1970-01-05 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 35 | 21 | 36.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 2022-10-17 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.08 | 0.0 | 0.0 | 67 | 54 | 58.0 | . 2022-10-18 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 58 | 48 | 56.0 | . 2022-10-19 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 56 | 43 | 61.0 | . 2022-10-20 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 61 | 44 | 64.0 | . 2022-10-21 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 64 | 43 | NaN | . 19287 rows × 8 columns . weather = weather.ffill() #fill the vaule . weather #one row having an incorrect target value will be insignificant with 20,000 rows in total . station name prcp snow snwd tmax tmin target . DATE . 1970-01-01 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 28 | 22 | 31.0 | . 1970-01-02 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 31 | 22 | 38.0 | . 1970-01-03 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.02 | 0.0 | 0.0 | 38 | 25 | 31.0 | . 1970-01-04 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 31 | 23 | 35.0 | . 1970-01-05 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 35 | 21 | 36.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 2022-10-17 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.08 | 0.0 | 0.0 | 67 | 54 | 58.0 | . 2022-10-18 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 58 | 48 | 56.0 | . 2022-10-19 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 56 | 43 | 61.0 | . 2022-10-20 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 61 | 44 | 64.0 | . 2022-10-21 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 64 | 43 | 64.0 | . 19287 rows × 8 columns . from sklearn.linear_model import Ridge #apply ridge regression model #&quot;Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity&quot; #&quot;Multicollinearity is a statistical concept where several independent variables in a model are correlated&quot; #ridge regression is similar to linear regression except that it penalizes coefficients to account for multicollinearity rr = Ridge(alpha=.1) #alpha parameter controls how much coefficeints are shrunk . predictors = weather.columns[~weather.columns.isin([&quot;target&quot;, &quot;name&quot;, &quot;station&quot;])] #create a list of predictor colomns #gives all the colomns in weather data except for these 3 # ~ negative operator looks for colomns not in the list . def backtest(weather, model, predictors, start=3650, step=90): all_predictions = [] for i in range(start, weather.shape[0], step): train = weather.iloc[:i,:] test = weather.iloc[i:(i+step),:] model.fit(train[predictors], train[&quot;target&quot;]) preds = model.predict(test[predictors]) preds = pd.Series(preds, index=test.index) combined = pd.concat([test[&quot;target&quot;], preds], axis=1) combined.columns = [&quot;actual&quot;, &quot;prediction&quot;] combined[&quot;diff&quot;] = (combined[&quot;prediction&quot;] - combined[&quot;actual&quot;]).abs() all_predictions.append(combined) return pd.concat(all_predictions) . predictions = backtest(weather, rr, predictors) . from sklearn.metrics import mean_absolute_error, mean_squared_error mean_absolute_error(predictions[&quot;actual&quot;], predictions[&quot;prediction&quot;]) . 5.13932667966084 . predictions.sort_values(&quot;diff&quot;, ascending=False) . actual prediction diff . DATE . 2007-03-26 78.0 | 49.744725 | 28.255275 | . 1999-01-02 53.0 | 25.911898 | 27.088102 | . 1998-03-26 80.0 | 53.033957 | 26.966043 | . 1985-04-18 84.0 | 57.071179 | 26.928821 | . 1990-03-12 85.0 | 58.144310 | 26.855690 | . ... ... | ... | ... | . 2006-08-20 88.0 | 88.002937 | 0.002937 | . 2019-03-01 40.0 | 40.002460 | 0.002460 | . 1992-06-11 76.0 | 76.001641 | 0.001641 | . 2011-09-16 66.0 | 66.000831 | 0.000831 | . 2014-03-25 39.0 | 38.999920 | 0.000080 | . 15637 rows × 3 columns . pd.Series(rr.coef_, index=predictors) . prcp -1.236110 snow -0.407827 snwd 0.053422 tmax 0.447413 tmin 0.517302 dtype: float64 . def pct_diff(old, new): return (new - old) / old def compute_rolling(weather, horizon, col): label = f&quot;rolling_{horizon}_{col}&quot; weather[label] = weather[col].rolling(horizon).mean() weather[f&quot;{label}_pct&quot;] = pct_diff(weather[label], weather[col]) return weather rolling_horizons = [3, 14] for horizon in rolling_horizons: for col in [&quot;tmax&quot;, &quot;tmin&quot;, &quot;prcp&quot;]: weather = compute_rolling(weather, horizon, col) . def expand_mean(df): return df.expanding(1).mean() for col in [&quot;tmax&quot;, &quot;tmin&quot;, &quot;prcp&quot;]: weather[f&quot;month_avg_{col}&quot;] = weather[col].groupby(weather.index.month, group_keys=False).apply(expand_mean) weather[f&quot;day_avg_{col}&quot;] = weather[col].groupby(weather.index.day_of_year, group_keys=False).apply(expand_mean) . weather = weather.iloc[14:,:] weather = weather.fillna(0) . predictors = weather.columns[~weather.columns.isin([&quot;target&quot;, &quot;name&quot;, &quot;station&quot;])] . predictions = backtest(weather, rr, predictors) mean_absolute_error(predictions[&quot;actual&quot;], predictions[&quot;prediction&quot;]) . 4.7928723896754235 . mean_squared_error(predictions[&quot;actual&quot;], predictions[&quot;prediction&quot;]) . 37.616408135652826 . predictions.sort_values(&quot;diff&quot;, ascending=False) #this table below are the predictions for each day minus the first 10 years. The first 10 years of data was used to train the model. . actual prediction diff . DATE . 1990-03-12 85.0 | 54.369353 | 30.630647 | . 2007-03-26 78.0 | 49.981156 | 28.018844 | . 1998-03-26 80.0 | 52.009052 | 27.990948 | . 2003-04-15 86.0 | 59.418323 | 26.581677 | . 1985-04-18 84.0 | 58.463358 | 25.536642 | . ... ... | ... | ... | . 2001-12-02 53.0 | 53.002346 | 0.002346 | . 1986-08-05 82.0 | 82.001182 | 0.001182 | . 1985-08-03 80.0 | 79.999022 | 0.000978 | . 1983-04-23 59.0 | 59.000813 | 0.000813 | . 2014-01-25 36.0 | 35.999195 | 0.000805 | . 15623 rows × 3 columns . weather.loc[&quot;1990-03-07&quot;: &quot;1990-03-17&quot;] . station name prcp snow snwd tmax tmin target rolling_3_tmax rolling_3_tmax_pct ... rolling_14_tmin rolling_14_tmin_pct rolling_14_prcp rolling_14_prcp_pct month_avg_tmax day_avg_tmax month_avg_tmin day_avg_tmin month_avg_prcp day_avg_prcp . DATE . 1990-03-07 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 2.0 | 32 | 14 | 39.0 | 33.666667 | -0.049505 | ... | 25.000000 | -0.440000 | 0.047857 | -1.000000 | 48.590112 | 45.428571 | 34.567783 | 31.857143 | 0.119410 | 0.111429 | . 1990-03-08 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 1.0 | 39 | 20 | 43.0 | 35.000000 | 0.114286 | ... | 24.071429 | -0.169139 | 0.040714 | -1.000000 | 48.574841 | 46.571429 | 34.544586 | 31.190476 | 0.119220 | 0.076667 | . 1990-03-09 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.01 | 0.0 | 0.0 | 43 | 29 | 47.0 | 38.000000 | 0.131579 | ... | 22.785714 | 0.272727 | 0.031429 | -0.681818 | 48.565978 | 45.619048 | 34.535771 | 30.952381 | 0.119046 | 0.036190 | . 1990-03-10 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.01 | 0.0 | 0.0 | 47 | 39 | 59.0 | 43.000000 | 0.093023 | ... | 23.428571 | 0.664634 | 0.020714 | -0.517241 | 48.563492 | 43.809524 | 34.542857 | 31.761905 | 0.118873 | 0.071905 | . 1990-03-11 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.05 | 0.0 | 0.0 | 59 | 41 | 59.0 | 49.666667 | 0.187919 | ... | 25.500000 | 0.607843 | 0.021429 | 1.333333 | 48.580032 | 46.142857 | 34.553090 | 31.904762 | 0.118764 | 0.126667 | . 1990-03-12 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 59 | 43 | 85.0 | 55.000000 | 0.072727 | ... | 27.928571 | 0.539642 | 0.021429 | -1.000000 | 48.596519 | 48.142857 | 34.566456 | 34.285714 | 0.118576 | 0.167619 | . 1990-03-13 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 85 | 41 | 62.0 | 67.666667 | 0.256158 | ... | 29.500000 | 0.389831 | 0.020000 | -1.000000 | 48.654028 | 48.761905 | 34.576619 | 34.285714 | 0.118389 | 0.091429 | . 1990-03-14 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 62 | 46 | 55.0 | 68.666667 | -0.097087 | ... | 30.857143 | 0.490741 | 0.020000 | -1.000000 | 48.675079 | 50.190476 | 34.594637 | 36.809524 | 0.118202 | 0.259524 | . 1990-03-15 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 55 | 43 | 62.0 | 67.333333 | -0.183168 | ... | 32.214286 | 0.334812 | 0.020000 | -1.000000 | 48.685039 | 49.714286 | 34.607874 | 35.761905 | 0.118016 | 0.066667 | . 1990-03-16 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.00 | 0.0 | 0.0 | 62 | 48 | 61.0 | 59.666667 | 0.039106 | ... | 33.428571 | 0.435897 | 0.020000 | -1.000000 | 48.705975 | 50.095238 | 34.628931 | 35.619048 | 0.117830 | 0.083810 | . 1990-03-17 USW00094789 | JFK INTERNATIONAL AIRPORT, NY US | 0.26 | 0.0 | 0.0 | 61 | 49 | 59.0 | 59.333333 | 0.028090 | ... | 34.357143 | 0.426195 | 0.038571 | 5.740741 | 48.725275 | 48.095238 | 34.651491 | 34.619048 | 0.118053 | 0.079048 | . 11 rows × 26 columns . (predictions[&quot;diff&quot;].round().value_counts().sort_index() / predictions.shape[0]).plot() . &lt;AxesSubplot:&gt; . predictions . actual prediction diff . DATE . 1980-01-13 54.0 | 32.430619 | 21.569381 | . 1980-01-14 51.0 | 44.600179 | 6.399821 | . 1980-01-15 45.0 | 46.846655 | 1.846655 | . 1980-01-16 40.0 | 42.211921 | 2.211921 | . 1980-01-17 41.0 | 40.865606 | 0.134394 | . ... ... | ... | ... | . 2022-10-17 58.0 | 67.303985 | 9.303985 | . 2022-10-18 56.0 | 62.355455 | 6.355455 | . 2022-10-19 61.0 | 59.688925 | 1.311075 | . 2022-10-20 64.0 | 62.128871 | 1.871129 | . 2022-10-21 64.0 | 63.122255 | 0.877745 | . 15623 rows × 3 columns .",
            "url": "https://sarayu-pr11.github.io/sarayucsa/2023/05/30/predict.html",
            "relUrl": "/2023/05/30/predict.html",
            "date": " • May 30, 2023"
        }
        
    
  
    
        ,"post3": {
            "title": "Step 1",
            "content": "Process . Using Python and machine learning to make weather predictions is a three-step process. . Download Data | Read in and clean the data | Train a machine learning model to make historical and future predictions | Make Predictions | Data . We got our from the NOAA, a U.S. government agency that forecasts weather. We downloaded data from New York because the weather has more variation than San Diego. The data was given to us in a .csv format . Cleaning Data . The first thing that we need to do when using data to teach an AI is to clean it. The data becomes useless if there is extraneous information to confuse the program. Additionally, if any of the columns have missing values, most machine learning models will not work with them. Our job is to first make a program that will remove those. . null_pct = weather.apply(pd.isnull).sum()/weather.shape[0] null_pct . First we&#39;re going to find the number of null values in each column. It will find out how many of the values are actually missing. By dividing the values by the total number of rows to get the percentage of null values. . valid_columns = weather.columns[null_pct &lt; 0.5] valid_columns weather = weather[valid_columns].copy() . This code snippet finds the colomns where the percentage of null values is less than 5%. Then it preserves only the valid colomns into &quot;weather&quot; . weather = weather.ffill() . This next line above fills in the remaining missing values in the preserved colomns. It fills it with the value from the day before. . weather.index = pd.to_datetime(weather.index) weather.index.year weather.index.year.value_counts().sort_index() . This changes our index to be stored as a date time, this way we can access the year of the index more easily. Then we are able to sort by year and it counts how many time the unique year value shows up (counting how many records there are for each year). This is a way to verify that every single day has data as all years should either have 365 or 366 records. . weather[&quot;target&quot;] = weather.shift(-1)[&quot;tmax&quot;] . Finally, we create a target colomn in the weather data for predictions . The next step is to get the data ready for machine learning. .",
            "url": "https://sarayu-pr11.github.io/sarayucsa/jupyter/2023/05/16/step1.html",
            "relUrl": "/jupyter/2023/05/16/step1.html",
            "date": " • May 16, 2023"
        }
        
    
  

  
  

  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sarayu-pr11.github.io/sarayucsa/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}