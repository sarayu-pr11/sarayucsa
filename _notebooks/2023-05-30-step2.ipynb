{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "> Steps after data cleaning\n",
    "- toc: true\n",
    "- categories: [jupyter]\n",
    "- comments: true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After data cleaning\n",
    "\n",
    "This is when you have to start assigning variables and labels to every instance, but before that, we need to make sure every spot has a value, even if it is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.ffill()\n",
    "#pull the temperature from a specific row and fil it in\n",
    "# in this case the last value \n",
    "# even though the value is wrong, we can't have missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start the predictions. Since we have multiple independent variables in the data (snow, rain, sleet, temperature), the data suffers from multicolinearity. Since this is the case, we need to use ridge regression. This type of model assumes that there is some sort of association between each of the variables and creates a prediction model accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rr = Ridge(alpha=.1)\n",
    "\n",
    "#we're going to apply a ridge regression model since the data sufferes from multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(weather, model, predictors, start=3650, step=90):\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(start, weather.shape[0], step):\n",
    "        train = weather.iloc[:i,:]\n",
    "        test = weather.iloc[i:(i+step),:]\n",
    "        \n",
    "        model.fit(train[predictors], train[\"target\"])\n",
    "        \n",
    "        preds = model.predict(test[predictors])\n",
    "        preds = pd.Series(preds, index=test.index)\n",
    "        combined = pd.concat([test[\"target\"], preds], axis=1)\n",
    "        combined.columns = [\"actual\", \"prediction\"]\n",
    "        combined[\"diff\"] = (combined[\"prediction\"] - combined[\"actual\"]).abs()\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "    return pd.concat(all_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs a backtesting analysis using a machine learning model. \n",
    "\n",
    "Here is a breakdown of what the code does.\n",
    "1. The function takes four parameters as input: weather (a DataFrame containing weather data), model (a machine learning model object), predictors (a list of predictor variables/columns from the weather DataFrame), start (an optional parameter specifying the starting index for the backtesting, default is 3650), and step (an optional parameter specifying the step size for each iteration of the backtesting, default is 90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. It initializes an empty list called all_predictions to store the predictions made during the backtesting.\n",
    "\n",
    "3. It starts a for loop that iterates over the range of indices from start to the total number of rows in the weather DataFrame with a step size of step. This loop allows the backtesting to be performed in multiple iterations with overlapping test sets.\n",
    "\n",
    "4. Within each iteration of the loop, it splits the weather DataFrame into a training set and a test set. The training set (train) includes all rows from the beginning up to the current index i, while the test set (test) includes the rows from i to i+step.\n",
    "\n",
    "5. The machine learning model (model) is trained using the predictor variables (predictors) from the training set (train) and the corresponding target variable (column) named \"target\" from the training set.\n",
    "\n",
    "6. The trained model is then used to make predictions on the predictor variables from the test set (test[predictors]). The predictions are stored in the preds variable.\n",
    "\n",
    "7. The predicted values are converted to a pandas Series (preds) with the same index as the test set (test.index).\n",
    "\n",
    "8. The actual target values and the predicted values are concatenated together into a DataFrame (combined) using pd.concat(). The columns of the DataFrame are renamed to \"actual\" and \"prediction\".\n",
    "\n",
    "9. A new column named \"diff\" is added to the DataFrame combined, which represents the absolute difference between the predicted and actual values.\n",
    "\n",
    "10. The DataFrame combined is appended to the all_predictions list.\n",
    "\n",
    "11. After the loop completes, all the prediction results from each iteration are concatenated together using pd.concat() and returned as the final result of the function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this code performs a backtesting analysis by training a machine learning model on the weather data and making predictions on overlapping test sets. It collects the predicted values, actual values, and the absolute difference between them in each iteration and returns the concatenated result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "name": "java"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
